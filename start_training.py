#!/usr/bin/env python3
"""
Quick Start Training for Enhanced Multi-Domain LLM
Run this to generate training data and start training process
"""

from enhanced_data_generator import EnhancedDataGenerator
from multi_domain_knowledge_base import Domain

def generate_training_data():
    """Generate comprehensive training dataset"""
    print("ğŸ¯ Generating Enhanced Multi-Domain Training Data")
    print("=" * 60)
    
    generator = EnhancedDataGenerator()
    
    # Generate large, balanced dataset
    print("ğŸ“Š Generating 15,000 training samples...")
    data = generator.generate_and_save_dataset(
        num_samples=15000,
        filename="enhanced_training_data.json",
        domain_distribution={
            Domain.MANIM: 0.4,          # 6,000 Manim samples
            Domain.DSA: 0.4,            # 6,000 DSA samples  
            Domain.SYSTEM_DESIGN: 0.2   # 3,000 System Design samples
        }
    )
    
    # Create train/validation split
    print("ğŸ“‚ Creating train/validation split...")
    train_data, val_data = generator.create_validation_split(data, split_ratio=0.85)
    
    # Save splits
    generator.save_training_data(train_data, "enhanced_train_data.json")
    generator.save_training_data(val_data, "enhanced_val_data.json")
    
    print("âœ… Training data generation complete!")
    print(f"ğŸ“ˆ Total samples: {len(data):,}")
    print(f"ğŸ‹ï¸ Training samples: {len(train_data):,}")
    print(f"âœ… Validation samples: {len(val_data):,}")
    
    return len(data)

def show_training_command():
    """Show command to start training"""
    print("\nğŸš€ TO START TRAINING:")
    print("=" * 60)
    print("1. First, generate training data:")
    print("   python3 start_training.py")
    print()
    print("2. Then, train the enhanced model:")
    print("   python3 train_model.py \\")
    print("     --train_data enhanced_train_data.json \\")
    print("     --val_data enhanced_val_data.json \\")
    print("     --model_type enhanced \\")
    print("     --epochs 15 \\")
    print("     --batch_size 8")
    print()
    print("3. After training, update your API:")
    print("   python3 fixed_api_server.py")
    print("=" * 60)

if __name__ == "__main__":
    # Generate data
    total_samples = generate_training_data()
    
    # Show next steps
    show_training_command()
    
    # Performance estimates
    print("\nğŸ“Š PERFORMANCE ESTIMATES:")
    print(f"ğŸ’¾ Dataset size: ~{total_samples * 0.5:.0f}MB")
    print("â±ï¸ Training time: 2-6 hours (depending on hardware)")
    print("ğŸ¯ Expected quality: 5x improvement over templates")
    print("ğŸš€ Domains supported: Manim + DSA + System Design")
    
    print("\nğŸ‰ Ready to train your enhanced multi-domain LLM!")